---
title: Data Science Zero to Hero - 2.3 Feature Engineering
date: 2023-06-28T00:00:00+00:00
summary: 
type: "blog"
draft: true
---
# Feature Engineering: Unleashing the Power of Data

Feature engineering and Feature Selection play a pivotal role in machine learning and data analysis. Feature Engineering and Feature Selection are similar terms, but play two slightly different roles in the Machine Learning Process.

__Feature engineering__ is the process of transforming raw data into informative and meaningful features that can improve the performance of predictive models. 

__Feature selection__, shares a similar name and purpose. Both feature engineering and feature selection are aimed at enhancing the performance of machine learning models. However, feature selection specifically focuses on the identification of the most relevant and "important" features that have the most significant impact on the model's predictive power and overall performance.

## Why we select (and engineer) our features!
Can engineer be used as a verb? I never excelled in English class... 

That aside, when we do feature engineering, it often involves the extraction, transformation, and creation of features from __raw data__ which helps machine learning algorithms understand the underlying patterns and relationships. It's a critical step in the machine learning cycle, as the quality and relevance of features heavily influence the performance of models. Some have called feature engineering an art - but that's up for debate!

Like we mentioned before, the ultimate goal of feature selection is to reduce the amount of data used in the dataset while at the same time improving the accuracy of the overall model. But how do you know which features to keep and which ones to get rid of? To accomplish this, feature selection methods typically rely on algorithms that identify features with the strongest correlations to the desired output.

In the following posts, we will look closer at various feature engineering and selection methods. 